{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "American Sign Language (ASL) is one of the main forms of communication among the deaf communities in United States\n",
    "and Canada. This motivates us to develop a translator that can recognize hand symbols and find the corresponding meaning. This would be useful aid for communication between deaf or mute people and those unfamiliar with sign language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Our goal is to develop a system and implement that system on a web app. We are trying to achieve it through following method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](img/model.png \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data-sets are from the University of Surrey. It has ≈ 400 images per letter per user for the 24 static letter symbols and 5 users under varying illumination and hand rotation conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "### 1. Skin detection\n",
    "\n",
    "#### 1.1 Gaussian curve modeling \n",
    "\n",
    "The first approach involved modeling the skin color by a 2D Gaussian curve and then using this fitted Gaussian to\n",
    "estimate the likelihood of a given color pixel being skin.\n",
    "\n",
    "First we need to collect skin patches and it's better to have patches collected from people belonging to different ethnicities so that our model is able to correctly predict skin areas for a wide variation of skin color. And then normalized each color (r=R/(R+G+B), b=B/(R+G+B)).Then estimate the mean and covariance matrix of the 2D Gaussian (with r, b as the axes) as Mean µ= E(x),Covariance C = E(x – µ)(x – µ)T, where x is the matrix with each row being the r and b values of a pixel. \n",
    "\n",
    "With this Gaussian fitted skin color model, compute the likelihood of skin for any pixel of a given test image. Threshold the likelihood to classify it as skin or non-skin.\n",
    "\n",
    "![Gaussian](img/Gaussian.png \"Gaussian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 YUV and YIQ space\n",
    "\n",
    "The second approach is that we need first transform the image from the RGB space to the YUV and YIQ color spaces. \n",
    "\n",
    "In YUV space, U and V are the orthogonal vectors on the plane. The chroma cue is a 2D vector, which is called as chroma cue vector. Every chroma cue vector represents a kind of color, meanwhile its saturation and hue are shown, respectively, by displacement, C and amplitude, θ\n",
    "\n",
    "$$C = \\sqrt{|U|^2 + |V|^2}$$\n",
    "\n",
    "$$θ=\\tan^{-1}(V/U)$$\n",
    "\n",
    "The skin chroma is between red and yellow. According to the analysis of the skin samples’ θ value, the chroma range can be obtained as [105,150]\n",
    "\n",
    "In YIQ space, the color saturation cue, I, is combined with θ to reinforce the segmentation effect. By the experimental results, in YIQ space the I value of skin color varies in a special area. The θ in YUV space and the I vector in YIQ space are taken as features to ascertain the chroma cue distributing area of skin color. The segmentation constraint is listed\n",
    "\n",
    "The color pixel point P is transformed from RGB space to YUV space and YIQ space,\n",
    "\n",
    "If 105∘⩽θ⩽150∘ and 30⩽I⩽100 then the pixel point belongs to the skin region.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. unsupervised learning features\n",
    "\n",
    "The method we want to use is called autoencoder, the extracted data of hand images was fed into an autoencoder in order to learn a set of unsupervised features.\n",
    "\n",
    "An autoencoder is an artificial neural network used for unsupervised learning of efficient codings. The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for the purpose of dimensionality reduction. The autoencoder concept is widely used for learning generative models of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. classification\n",
    "The next step was to train a softmax classifier based on the features learnt by the autoencoder. The activations of the hidden layer of the autoencoder was fed into a softmax classifier. And finally test our model by our test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
